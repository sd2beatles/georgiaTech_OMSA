{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uS6np4mrHQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "#uploaded = files.upload()\n",
        "# import io\n",
        "# df2 = pd.read_csv(io.BytesIO(uploaded['Formula1.csv']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqtv8Q7TdQhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3svinC8xJe4N",
        "colab_type": "text"
      },
      "source": [
        "# Collecting  Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyNkVjDS2Bxs",
        "colab_type": "code",
        "outputId": "ee3c16fa-b97a-4534-8d17-de1772f2723b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "\n",
        "Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\", width=500, height=250)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\" width=\"500\" height=\"250\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2It_WiEyRU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#collect MNIST data\n",
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUU_qZ4z3oRt",
        "colab_type": "code",
        "outputId": "2ce41dc9-dcda-4d07-e0fd-127c32f94ce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "print(f'the shape of x_train:{x_train.shape}')\n",
        "print(f'the shape of x_test{x_test.shape}')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the shape of x_train:(60000, 28, 28)\n",
            "the shape of x_test(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0fGoXhAIo2r",
        "colab_type": "text"
      },
      "source": [
        "We can see that each image consists of a 28*28 pixel image and is a handwritten number.Additionally, we should note that MNIST scales from 0 to 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWnSzkUTJlsJ",
        "colab_type": "text"
      },
      "source": [
        "# Split the data into train and validated data\n",
        "\n",
        "After setting up the model, we need to train it with a sample of so-called training data. However, if this procedure proceeds only based on the training data, our model is learning noises in an unwanted manner, which leads our model to show a high level of performance on the training set but a lower level on the newly entered data -overfitting problem.\n",
        "\n",
        "Therefore, we need to come out with another dataset to evaluate a given model fit on the training set while tunning hyperparameters. This is where validation sets kick in.  This gives guides as to how many iterations should be run before the model is suffering from overfitting.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/53164959/75613159-beddef00-5b6d-11ea-9d76-e065c0622e1d.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hin9blKgyw3j",
        "colab_type": "code",
        "outputId": "bc20b489-0bb1-40bc-b78d-3a207e75f43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x_val=x_train[50000:60000]\n",
        "x_train=x_train[0:50000]\n",
        "y_val=y_train[50000:60000]\n",
        "y_train=y_train[0:50000]\n",
        "\n",
        "print(f'x_train samples:{x_train.shape[0]}, x_train image pixels: {x_train.shape[1]}*{x_train.shape[2]}')\n",
        "print(f'x_val samples:{x_val.shape[0]}, x_val image pixels: {x_val.shape[1]}*{x_val.shape[2]}')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train samples:50000, x_train image pixels: 28*28\n",
            "x_val samples:10000, x_val image pixels: 28*28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4cuNPBGRDMf",
        "colab_type": "text"
      },
      "source": [
        "# Reshaping Our image data\n",
        "\n",
        "In order to recoginze the handwritten digits, our very first step is to put the all information to a neural network. This begins as 756 items are now conneted to each input nodes in our model. This indireclty explains why we need to flattenour the shape of column to make the first dimension array.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/53164959/75613385-60fed680-5b70-11ea-8102-567f9c2c55fd.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m17Rrxu-PlJs",
        "colab_type": "code",
        "outputId": "4a550d70-1d4b-4008-c09f-21bf30232e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "x_train=x_train.reshape(50000,784)\n",
        "x_val=x_val.reshape(10000,784)\n",
        "x_test=x_test.reshape(10000,784)\n",
        "\n",
        "print(f'x_train shape: {x_train.shape}')\n",
        "print(f'x_val shape: {x_val.shape}')\n",
        "print(f'x_test shape: {x_test.shape}')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 784)\n",
            "x_val shape: (10000, 784)\n",
            "x_test shape: (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFtvlz3EUUTA",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiwS97nZWeBQ",
        "colab_type": "text"
      },
      "source": [
        "# Why Normalization Required?\n",
        "Having all scaled inputs to a neural network contributes to the conversion of error surface into a more spherical shape. This helps the Gradient Descent converge faster to the global minimum. That is why he mentions the convergence is fast and improved.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGzYigOCRCyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=x_train.astype(np.float32)\n",
        "x_val=x_val.astype(np.float32)\n",
        "x_test=x_test.astype(np.float32)\n",
        "\n",
        "#Note that mnist scales from 0 to 255 where 0 indicates there is no hand written.\n",
        "gray_scale=255\n",
        "x_train/=gray_scale\n",
        "x_val/=gray_scale\n",
        "x_test/=gray_scale\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4pDYLYCTQjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTidZZyl4Y8K",
        "colab_type": "text"
      },
      "source": [
        "# Creation of Dummy Variable\n",
        "\n",
        "We need to convert labels into variable taking either 0 or 1. This ca be done through one hot encoding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_5Oj7L65U_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes=10\n",
        "y_train=tf.keras.utils.to_categorical(y_train,num_classes)\n",
        "y_val=tf.keras.utils.to_categorical(y_val,num_classes)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWT6UFsZ51nf",
        "colab_type": "text"
      },
      "source": [
        "# Construction of Layers in the  MLP \n",
        "\n",
        "![image](https://user-images.githubusercontent.com/53164959/75618281-5152b280-5baf-11ea-8aea-d9c410bd7063.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf9Yk00Z5zaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "x=tf.placeholder(tf.float32,[None,784])\n",
        "y=tf.placeholder(tf.float32,[None,10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfpqU3An6rNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp(x):\n",
        "    # hidden layer1\n",
        "    w1 = tf.Variable(tf.random_uniform([784,256]))\n",
        "    b1 = tf.Variable(tf.zeros([256]))\n",
        "    h1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
        "    # hidden layer2\n",
        "    w2 = tf.Variable(tf.random_uniform([256,128]))\n",
        "    b2 = tf.Variable(tf.zeros([128]))\n",
        "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
        "    # output layer\n",
        "    w3 = tf.Variable(tf.random_uniform([128,10]))\n",
        "    b3 = tf.Variable(tf.zeros([10]))\n",
        "    logits= tf.matmul(h2, w3) + b3\n",
        "    \n",
        "    return logits\n",
        "logits = mlp(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ugV0l-Z8yWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-Y6ax5-83FP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_op=tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWHkRuEu-ZjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "ec7de199-72ee-4893-f7f3-c5bd9f3676bf"
      },
      "source": [
        "#intialize\n",
        "init=tf.global_variables_initializer()\n",
        "\n",
        "#train_hyperparameter\n",
        "epoch_cnt=30\n",
        "batch_size=1000\n",
        "iteration=len(x_train)//batch_size\n",
        "\n",
        "#start training\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(epoch_cnt):\n",
        "    avg_loss=0\n",
        "    start=0;end=batch_size\n",
        "    \n",
        "    #Each for loop amounts to 50. After an iteration, strat and end increase by 1000\n",
        "    for i in range(iteration):\n",
        "      _,loss=sess.run([train_op,loss_op],feed_dict={x:x_train[start:end],y:y_train[start:end]})\n",
        "      start+=batch_size;end+=batch_size\n",
        "      #compute the average loss\n",
        "      avg_loss+=loss/iteration\n",
        "    #After training,we are ready to bring the predicted numbers\n",
        "    preds=tf.nn.softmax(logits)\n",
        "    correct=tf.equal(tf.argmax(preds,axis=1),tf.argmax(y,axis=1))\n",
        "    accuracy=tf.reduce_mean(tf.cast(correct,tf.float32))\n",
        "    cur_val_acc=accuracy.eval({x:x_val,y:y_val})\n",
        "    print(f\"epoch:{epoch},validation_accuracy:{cur_val_acc},loss:{avg_loss}\")\n",
        "# Test model\n",
        "  preds = tf.nn.softmax(logits)  # Apply softmax to logits\n",
        "  correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  print(\"[Test Accuracy] :\", accuracy.eval({x: x_test, y: y_test}))\n",
        " \n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0,validation_accuracy:0.09880000352859497,loss:8542.699897460941\n",
            "epoch:1,validation_accuracy:0.7709000110626221,loss:399.82943786621087\n",
            "epoch:2,validation_accuracy:0.8824999928474426,loss:17.521709346771246\n",
            "epoch:3,validation_accuracy:0.8885999917984009,loss:10.472563209533691\n",
            "epoch:4,validation_accuracy:0.8982999920845032,loss:8.075983915328978\n",
            "epoch:5,validation_accuracy:0.8888999819755554,loss:6.677321166992188\n",
            "epoch:6,validation_accuracy:0.8902000188827515,loss:5.641556367874146\n",
            "epoch:7,validation_accuracy:0.8967999815940857,loss:5.099739503860472\n",
            "epoch:8,validation_accuracy:0.8967999815940857,loss:4.386400728225707\n",
            "epoch:9,validation_accuracy:0.911899983882904,loss:5.494774961471557\n",
            "epoch:10,validation_accuracy:0.8722000122070312,loss:4.480757584571838\n",
            "epoch:11,validation_accuracy:0.9122999906539917,loss:6.228302817344666\n",
            "epoch:12,validation_accuracy:0.8841000199317932,loss:4.498648958206176\n",
            "epoch:13,validation_accuracy:0.8503000140190125,loss:13.00392523765564\n",
            "epoch:14,validation_accuracy:0.9169999957084656,loss:6.132960000038146\n",
            "epoch:15,validation_accuracy:0.9142000079154968,loss:4.262549557685853\n",
            "epoch:16,validation_accuracy:0.8835999965667725,loss:4.865891427993775\n",
            "epoch:17,validation_accuracy:0.8964999914169312,loss:6.995614800453184\n",
            "epoch:18,validation_accuracy:0.9099000096321106,loss:4.8158707141876205\n",
            "epoch:19,validation_accuracy:0.9081000089645386,loss:3.3174623656272897\n",
            "epoch:20,validation_accuracy:0.9121999740600586,loss:3.546202640533447\n",
            "epoch:21,validation_accuracy:0.9104999899864197,loss:3.781855273246766\n",
            "epoch:22,validation_accuracy:0.9114999771118164,loss:3.9652560639381416\n",
            "epoch:23,validation_accuracy:0.9085999727249146,loss:3.1554954624176026\n",
            "epoch:24,validation_accuracy:0.8888000249862671,loss:3.2952067184448235\n",
            "epoch:25,validation_accuracy:0.8751999735832214,loss:3.969343476295471\n",
            "epoch:26,validation_accuracy:0.9045000076293945,loss:4.147177133560181\n",
            "epoch:27,validation_accuracy:0.9107999801635742,loss:3.079639089107513\n",
            "epoch:28,validation_accuracy:0.9002000093460083,loss:2.351203894615174\n",
            "epoch:29,validation_accuracy:0.9164000153541565,loss:2.5831186318397523\n",
            "[Test Accuracy] : 0.9125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vRyTJInECkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}